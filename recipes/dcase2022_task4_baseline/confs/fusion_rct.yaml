training:
  #batch size: [synth, weak, unlabel]
  batch_size: [12, 12, 24]
  batch_size_val: 24
  const_max: 1 # max weight used for self supervised loss
  n_epochs_warmup: 50 # num epochs used for exponential warmup
  num_workers: 6 # change according to your cpu
  n_epochs: 200 # max num epochs
  early_stop_patience: 50 # Same as number of epochs by default, so no early stopping used
  accumulate_batches: 1
  gradient_clip: 0. # 0 no gradient clipping
  median_window: 7
  test_temp: 3
  val_thresholds: [0.5] # thresholds used to compute f1 intersection in validation.
  n_test_thresholds: 50 # number of thresholds used to compute psds in test
  ema_factor: 0.999 # ema factor for mean teacher
  self_sup_loss: mse # bce or mse for self supervised mean teacher loss
  backend: # pytorch lightning backend, ddp, dp or None
  validation_interval: 1 # perform validation every X epoch, 1 default
  weak_split: 0.9
  seed: 42
  mixup: soft # Soft mixup gives the ratio of the mix to the labels, hard mixup gives a 1 to every label present.
  obj_metric_synth_type: intersection
scaler:
  statistic: instance # instance or dataset-wide statistic
  normtype: minmax # minmax or standard or mean normalization
  dims: [1, 2] # dimensions over which normalization is applied
  savepath: ./scaler.ckpt # path to scaler checkpoint
data: # change with your paths if different.
  # NOTE: if you have data in 44kHz only then synth_folder will be the path where
  # resampled data will be placed.
  synth_folder: "YOUR_PATH/audio/train/synthetic21_train/soundscapes_16k/"
  synth_folder_44k: "YOUR_PATH/audio/train/synthetic21_train/soundscapes/"
  synth_tsv:  "YOUR_PATH/metadata/train/synthetic21_train/soundscapes.tsv"
  weak_folder: "YOUR_PATH/audio/train/weak_16k/"
  weak_folder_44k: "YOUR_PATH/audio/train/weak/"
  weak_tsv: "YOUR_PATH/metadata/train/weak.tsv"
  strong_folder: "YOUR_PATH/audio/train/strong_label_real_16k/"
  strong_folder_44k: "YOUR_PATH/audio/train/strong_label_real/"
  strong_tsv: "YOUR_PATH/metadata/train/audioset_strong.tsv"
  unlabeled_folder: "YOUR_PATH/audio/train/unlabel_in_domain_16k/"
  unlabeled_folder_44k: "YOUR_PATH/audio/train/unlabel_in_domain/"
  synth_val_folder: "YOUR_PATH/audio/validation/synthetic21_validation/soundscapes_16k/"
  synth_val_folder_44k: "/data/home/shaonian/Datasets/DCASE/case/dataset/audio/validation/synthetic21_validation/soundscapes/"
  synth_val_tsv:  "YOUR_PATH/metadata/validation/synthetic21_validation/soundscapes.tsv"
  synth_val_dur: "YOUR_PATH/metadata/validation/synthetic21_validation/durations.tsv"
  test_folder: "YOUR_PATH/audio/validation/validation_16k/"
  test_folder_44k: "YOUR_PATH/audio/validation/validation/"
  test_tsv: "YOUR_PATH/metadata/validation/validation.tsv"
  test_dur: "YOUR_PATH/metadata/validation/validation_durations.tsv"
  eval_folder: "YOUR_PATH/audio/eval21_16k/"
  eval_folder_44k: "YOUR_PATH/audio/eval21/"
  audio_max_len: 10
  fs: 16000
  net_subsample: 4
opt:
  lr: 0.001
feats:
  n_mels: 128
  n_filters: 2048
  hop_length: 160
  n_window: 2048
  sample_rate: 16000
  f_min: 0
  f_max: 8000
net:
  atst_mode: base  # small or base
  pretrained_ckpt_path: "./pretraining/ATST/base/rct.ckpt"
  pretrained_crnn: "./pretraining/CNN/rct.ckpt"
  freeze_cnn: False
  audio_len: 10
  n_last_blocks: 2
  n_class: 10
  chunk_input: False
  unfreeze: 3
  rct_atst_weights: "./pretraining/ATST/base/rct.ckpt"
  ast:
    patch_h: 64
    patch_w: 4
    use_cls: True
    spec_h: 64
    spec_w: 1001
    in_chans: 1
    num_classes: 10
    mlp_ratio: 4.
    qk_scale: None
    drop_rate: 0.
    attn_drop_rate: 0.
    drop_path_rate: 0.1
    mask_ratio: 0
    pos_type: "cut"
  crnn:
    dropout: 0.5
    rnn_layers: 2
    n_in_channel: 1
    nclass: 10
    attention: True
    n_RNN_cell: 512
    activation: cg
    rnn_type: BGRU
    kernel_size: [ 3, 3, 3, 3, 3, 3, 3 ]
    padding: [ 1, 1, 1, 1, 1, 1, 1 ]
    stride: [ 1, 1, 1, 1, 1, 1, 1 ]
    nb_filters: [ 16, 32, 64, 128, 128, 128, 128 ]
    pooling: [ [ 2, 2 ], [ 2, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ] ]
    dropout_recurrent: 0
    atst_res_block: False
augs:
  mixup: HARD          # Can only be HARD | NULL
  mixup_scale: [1, 2]
  aug_methods: ["Time mask", "Time shift", "Filter"] # ["Pitch shift", "Time mask", "Time shift", "Frequency mask", "Filter"]
  aug_scale: 5
  unsup: True             # Whether to augment unsupervised data
  consis: True            # Whether to use consistency loss
  consis_loss: mse
